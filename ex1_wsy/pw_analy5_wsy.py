import re
import os
import matplotlib.pyplot as plt
from wordfreq import zipf_frequency
from collections import Counter

# ========== å…¨å±€å‚æ•° ==========
TOPK = 10
OUTPUT_DIR = "5_english_word_analysis_results"
os.makedirs(OUTPUT_DIR, exist_ok=True)
REPORT_PATH = os.path.join(OUTPUT_DIR, "è‹±æ–‡å•è¯ä½¿ç”¨åˆ†ææŠ¥å‘Š.txt")

FILE1 = "plaintxt_yahoo.txt"
FILE2 = "www.csdn.net.sql"
COUNT_MODE = 'unique_per_password'  # æ¯ä¸ªå¯†ç åªç»Ÿè®¡ä¸€æ¬¡å•è¯

# ========== å™ªå£°è¿‡æ»¤æœºåˆ¶ ==========
COMMON_NON_WORDS = [
    r'^[a-z]{1,2}$',                      # è¿‡çŸ­å­—æ¯ä¸²
    r'^(qwe|asd|zxc|poi|lkj|mnb|qaz|wsx|edc|abc)+$',  # é”®ç›˜åºåˆ—
    r'^(aaa|bbb|ccc|ddd|eee|fff)+$',      # é‡å¤å­—æ¯
]

PINYIN_SURNAMES = {
    'wang', 'li', 'zhang', 'liu', 'chen', 'yang', 'zhao', 'wu', 'zhou', 'xu',
    'sun', 'hu', 'zhu', 'gao', 'lin', 'he', 'guo', 'ma', 'lu', 'dong', 'xie',
    'song', 'shi', 'tang', 'feng', 'yu', 'cai', 'pan', 'deng', 'xiao', 'tian',
    'liang', 'wei', 'jiang', 'han', 'fan', 'peng', 'yuan', 'cao', 'fu', 'ren',
    'fang', 'jing', 'cheng', 'qian', 'mo', 'qiu', 'long', 'chang',
    'qiao', 'mei', 'hua', 'jin', 'tao', 'qi', 'wen', 'yan', 'bao', 'du',
    'ye', 'su', 'pei', 'luo', 'shan', 'hou', 'qin', 'ruan', 'tan', 'lv'
}

def is_noise_word(word):
    if word in PINYIN_SURNAMES:
        return True
    for pat in COMMON_NON_WORDS:
        if re.fullmatch(pat, word):
            return True
    return False

def is_common_english_word(word, min_freq=3.0):
    """ç”¨ wordfreq åˆ¤æ–­æ˜¯å¦ä¸ºå¸¸è§è‹±æ–‡å•è¯"""
    return zipf_frequency(word, 'en') >= min_freq

# ========== æ–‡ä»¶è¯»å– ==========
def extract_password_yahoo(line):
    parts = line.strip().split(":")
    if len(parts) >= 3:
        return parts[-1].strip()
    return None

def extract_password_csdn(line):
    match = re.search(r"#\s*(.*?)\s*#", line)
    if match:
        return match.group(1).strip()
    return None

def load_passwords(filename):
    passwords = []
    try:
        with open(filename, "r", encoding="utf-8", errors="ignore") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                if "yahoo" in filename.lower():
                    pwd = extract_password_yahoo(line)
                elif "csdn" in filename.lower():
                    pwd = extract_password_csdn(line)
                else:
                    pwd = line.strip()
                if pwd:
                    passwords.append(pwd)
    except Exception as e:
        print(f"[é”™è¯¯] æ— æ³•è¯»å– {filename}: {e}")

    print(f"[INFO] æˆåŠŸè¯»å– {len(passwords)} æ¡å¯†ç æ¥è‡ª {filename}")
    return passwords

# ========== è´ªå¿ƒæ‹†åˆ†å‡½æ•° ==========
def greedy_word_split_case_insensitive(segment, min_freq):
    """
    å¤§å°å†™æ— å…³çš„è´ªå¿ƒæœ€å¤§åŒ¹é…æ‹†åˆ†ã€‚
    è¿”å›æ‹†åˆ†åçš„å•è¯åˆ—è¡¨ï¼ˆå°å†™ï¼‰
    """
    segment_lower = segment.lower()
    i = 0
    n = len(segment_lower)
    results = []
    while i < n:
        match = None
        for j in range(n, i, -1):
            sub = segment_lower[i:j]
            if is_common_english_word(sub, min_freq=min_freq):
                match = sub
                results.append(sub)
                i = j
                break
        if not match:
            i += 1
    return results

# ========== æå–è‹±æ–‡å•è¯å‡½æ•° ==========
def extract_valid_words(pwd, min_freq):
    """
    æå–è‹±æ–‡å•è¯ï¼ŒåŒæ—¶ç»Ÿè®¡å¤§å°å†™æ¨¡å¼
    """
    candidates = re.findall(r"[A-Za-z]+", pwd)
    validated = []
    seen_in_pwd = set()
    case_patterns = []

    for seg in candidates:
        splits = greedy_word_split_case_insensitive(seg, min_freq)

        idx = 0  # å›æº¯åŸå§‹å¤§å°å†™
        for w_lower in splits:
            w_orig = seg[idx:idx+len(w_lower)]
            idx += len(w_lower)

            if len(w_lower) < 3 or len(w_lower) > 15:
                continue
            if is_noise_word(w_lower):
                continue
            if not is_common_english_word(w_lower, min_freq=min_freq):
                continue
            if COUNT_MODE == 'unique_per_password' and w_lower in seen_in_pwd:
                continue

            seen_in_pwd.add(w_lower)
            validated.append(w_orig)

            # å¤§å°å†™æ¨¡å¼
            if w_orig.islower():
                case_patterns.append('lower')
            elif w_orig.isupper():
                case_patterns.append('upper')
            elif w_orig[0].isupper() and w_orig[1:].islower():
                case_patterns.append('capitalized')
            else:
                case_patterns.append('mixed')

    return validated, case_patterns

# ========== è‹±æ–‡å•è¯åˆ†æ ==========
def analyze_english_words(passwords, label, report_file, min_freq_all=3.0, min_freq_top=5.0):
    all_words = []
    all_cases = []
    word_in_pwd = 0

    for pwd in passwords:
        words, case_patterns = extract_valid_words(pwd, min_freq=min_freq_all)
        if words:
            word_in_pwd += 1
            all_words.extend(words)
            all_cases.extend(case_patterns)

    report_file.write(f"\n========= {label} è‹±æ–‡å•è¯ç»Ÿè®¡ =========\n")
    report_file.write(f"å¯†ç æ€»æ•°: {len(passwords)}\n")
    report_file.write(f"åŒ…å«è‹±æ–‡å•è¯çš„å¯†ç æ•°: {word_in_pwd} ({word_in_pwd / len(passwords) * 100:.2f}%)\n")
    report_file.write(f"ï¼ˆå·²å¯ç”¨å™ªå£°è¿‡æ»¤ï¼Œç»Ÿè®¡min_freq={min_freq_all}ï¼Œç­›é€‰min_freq={min_freq_top}ï¼‰\n\n")

    # Top10 é«˜é¢‘å•è¯
    counter = Counter(all_words)
    high_freq_words = [w for w in counter if is_common_english_word(w.lower(), min_freq=min_freq_top)]
    top_high_freq = sorted(((w, counter[w]) for w in high_freq_words), key=lambda x: x[1], reverse=True)[:TOPK]

    report_file.write(f"Top{TOPK} é«˜é¢‘è‹±æ–‡å•è¯ (min_freq={min_freq_top}):\n")
    for w, c in top_high_freq:
        report_file.write(f"{w}: {c}\n")

    # å¤§å°å†™æ¨¡å¼ç»Ÿè®¡
    case_counter = Counter(all_cases)
    report_file.write("\nè‹±æ–‡å•è¯å¤§å°å†™æ¨¡å¼ç»Ÿè®¡:\n")
    for case, count in case_counter.items():
        report_file.write(f"{case}: {count}\n")

    # === å›¾è¡¨ç»˜åˆ¶ ===
    if top_high_freq:
        plt.figure(figsize=(8, 4))
        plt.bar([w for w, _ in top_high_freq], [c for _, c in top_high_freq], color='lightgreen')
        plt.title(f"{label} Top-{TOPK} Frequent English Words", fontsize=12)
        plt.xlabel("Word")
        plt.ylabel("Count")
        plt.xticks(rotation=45)
        plt.tight_layout()
        plt.savefig(os.path.join(OUTPUT_DIR, f"{label}_top_words.png"))
        plt.close()

    if case_counter:
        sorted_cases = sorted(case_counter.items(), key=lambda x: x[1], reverse=True)
        plt.figure(figsize=(6, 4))
        plt.bar([case for case, _ in sorted_cases], [count for _, count in sorted_cases], color='orange')
        plt.title(f"{label} Case Patterns (Sorted by Count)", fontsize=12)
        plt.xlabel("Case")
        plt.ylabel("Count")
        plt.tight_layout()
        plt.savefig(os.path.join(OUTPUT_DIR, f"{label}_case_patterns.png"))
        plt.close()

        # === é¥¼çŠ¶å›¾ ===
        plt.figure(figsize=(6, 6))
        plt.pie(
            [count for _, count in sorted_cases],
            labels=[case for case, _ in sorted_cases],
            autopct='%1.1f%%',
            startangle=140
        )
        plt.title(f"{label} Case Patterns Distribution (Pie Chart)", fontsize=12)
        plt.tight_layout()
        plt.savefig(os.path.join(OUTPUT_DIR, f"{label}_case_patterns_pie.png"))
        plt.close()


# ========== ä¸»ç¨‹åºå…¥å£ ==========
def main():
    print("=" * 60)
    print("è‹±æ–‡å•è¯è¯†åˆ«ä¸ä½¿ç”¨ç»Ÿè®¡åˆ†æ")
    print("=" * 60)
    print(f"æ–‡ä»¶1: {FILE1}")
    print(f"æ–‡ä»¶2: {FILE2}")
    print(f"è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print("=" * 60, "\n")

    pwds1 = load_passwords(FILE1)
    pwds2 = load_passwords(FILE2)

    with open(REPORT_PATH, "w", encoding="utf-8") as report_file:
        analyze_english_words(pwds1, "Yahoo", report_file, min_freq_all=3.0, min_freq_top=5.0)
        analyze_english_words(pwds2, "CSDN", report_file, min_freq_all=3.0, min_freq_top=5.0)

    print(f"âœ… è‹±æ–‡å•è¯åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜è‡³: {REPORT_PATH}")
    print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜è‡³: {OUTPUT_DIR}")

if __name__ == "__main__":
    main()
